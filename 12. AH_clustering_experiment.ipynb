{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nadee\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.neighbors.nearest_centroid module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors.nearest_centroid import NearestCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('FINAL_FINAL_SCALED_DATA.csv') \n",
    "\n",
    "df = pd.DataFrame(data, columns=['feature', 'feature_neutral', 'feature_frequency', 'feature_dissatisfaction','feature_satisfaction', 'hungerstation_e', 'h_dissatisfaction', 'h_satisfaction', 'jahez_e', 'j_dissatisfaction', 'j_satisfaction', 'shgardi_e', 's_dissatisfaction', 's_satisfaction', 'toyou_e', 't_dissatisfaction', 't_satisfaction', 'thechefz_e', 'c_dissatisfaction', 'c_satisfaction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(df)):\n",
    "    if df['feature_satisfaction'][x] == 0 and df['feature_dissatisfaction'][x] == 0:\n",
    "        print(df['feature'][x])\n",
    "        df.drop(x, inplace=True)\n",
    "        \n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = df[['feature_dissatisfaction','feature_satisfaction']].to_numpy()\n",
    "# points = df[['feature_dissatisfaction','feature_satisfaction', 'hungerstation_e', 'h_dissatisfaction', 'h_satisfaction', 'jahez_e', 'j_dissatisfaction', 'j_satisfaction', 'shgardi_e', 's_dissatisfaction', 's_satisfaction', 'toyou_e', 't_dissatisfaction', 't_satisfaction', 'thechefz_e', 'c_dissatisfaction', 'c_satisfaction']].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "y = cluster.fit_predict(points)\n",
    "df['cluster'] = cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {'feature': [], \"cluster\": [], \"feature_dissatisfaction\": [], \"feature_satisfaction\": [], \"feature_neutral\": [], \"feature_frequency\": [], 'hungerstation_e': [], 'h_dissatisfaction':[], 'h_satisfaction': [], 'jahez_e': [], 'j_dissatisfaction':[], 'j_satisfaction': [], 'shgardi_e': [], 's_dissatisfaction':[], 's_satisfaction': [], 'toyou_e': [], 't_dissatisfaction':[], 't_satisfaction': [], 'thechefz_e': [], 'c_dissatisfaction':[], 'c_satisfaction': []}\n",
    "\n",
    "for x in range(len(df)):\n",
    "        table[\"feature\"].append(df['feature'][x])\n",
    "        table[\"cluster\"].append(df['cluster'][x])\n",
    "        \n",
    "        table[\"feature_dissatisfaction\"].append(df['feature_dissatisfaction'][x])\n",
    "        table[\"feature_satisfaction\"].append(df['feature_satisfaction'][x])\n",
    "        table[\"feature_neutral\"].append(df['feature_neutral'][x])\n",
    "        table[\"feature_frequency\"].append(df['feature_frequency'][x])\n",
    "            \n",
    "        table[\"hungerstation_e\"].append(df['hungerstation_e'][x])\n",
    "        table[\"h_dissatisfaction\"].append(df['h_dissatisfaction'][x])\n",
    "        table[\"h_satisfaction\"].append(df['h_satisfaction'][x])\n",
    "\n",
    "        table[\"jahez_e\"].append(df['jahez_e'][x])\n",
    "        table[\"j_dissatisfaction\"].append(df['j_dissatisfaction'][x])\n",
    "        table[\"j_satisfaction\"].append(df['j_satisfaction'][x])\n",
    "\n",
    "        table[\"shgardi_e\"].append(df['shgardi_e'][x])\n",
    "        table[\"s_dissatisfaction\"].append(df['s_dissatisfaction'][x])\n",
    "        table[\"s_satisfaction\"].append(df['s_satisfaction'][x])\n",
    "\n",
    "        table[\"toyou_e\"].append(df['toyou_e'][x])\n",
    "        table[\"t_dissatisfaction\"].append(df['t_dissatisfaction'][x])\n",
    "        table[\"t_satisfaction\"].append(df['t_satisfaction'][x])\n",
    "\n",
    "        table[\"thechefz_e\"].append(df['thechefz_e'][x])\n",
    "        table[\"c_dissatisfaction\"].append(df['c_dissatisfaction'][x])\n",
    "        table[\"c_satisfaction\"].append(df['c_satisfaction'][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_dict(table,orient='index').transpose()\n",
    "df.to_csv('ah_3_clusters_2v_NEW.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = AgglomerativeClustering(n_clusters=4, affinity='euclidean', linkage='ward')\n",
    "y = cluster.fit_predict(points)\n",
    "df['cluster'] = cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {'feature': [], \"cluster\": [], \"feature_dissatisfaction\": [], \"feature_satisfaction\": [], \"feature_neutral\": [], \"feature_frequency\": [], 'hungerstation_e': [], 'h_dissatisfaction':[], 'h_satisfaction': [], 'jahez_e': [], 'j_dissatisfaction':[], 'j_satisfaction': [], 'shgardi_e': [], 's_dissatisfaction':[], 's_satisfaction': [], 'toyou_e': [], 't_dissatisfaction':[], 't_satisfaction': [], 'thechefz_e': [], 'c_dissatisfaction':[], 'c_satisfaction': []}\n",
    "\n",
    "for x in range(len(df)):\n",
    "        table[\"feature\"].append(df['feature'][x])\n",
    "        table[\"cluster\"].append(df['cluster'][x])\n",
    "        \n",
    "        table[\"feature_dissatisfaction\"].append(df['feature_dissatisfaction'][x])\n",
    "        table[\"feature_satisfaction\"].append(df['feature_satisfaction'][x])\n",
    "        table[\"feature_neutral\"].append(df['feature_neutral'][x])\n",
    "        table[\"feature_frequency\"].append(df['feature_frequency'][x])\n",
    "            \n",
    "        table[\"hungerstation_e\"].append(df['hungerstation_e'][x])\n",
    "        table[\"h_dissatisfaction\"].append(df['h_dissatisfaction'][x])\n",
    "        table[\"h_satisfaction\"].append(df['h_satisfaction'][x])\n",
    "\n",
    "        table[\"jahez_e\"].append(df['jahez_e'][x])\n",
    "        table[\"j_dissatisfaction\"].append(df['j_dissatisfaction'][x])\n",
    "        table[\"j_satisfaction\"].append(df['j_satisfaction'][x])\n",
    "\n",
    "        table[\"shgardi_e\"].append(df['shgardi_e'][x])\n",
    "        table[\"s_dissatisfaction\"].append(df['s_dissatisfaction'][x])\n",
    "        table[\"s_satisfaction\"].append(df['s_satisfaction'][x])\n",
    "\n",
    "        table[\"toyou_e\"].append(df['toyou_e'][x])\n",
    "        table[\"t_dissatisfaction\"].append(df['t_dissatisfaction'][x])\n",
    "        table[\"t_satisfaction\"].append(df['t_satisfaction'][x])\n",
    "\n",
    "        table[\"thechefz_e\"].append(df['thechefz_e'][x])\n",
    "        table[\"c_dissatisfaction\"].append(df['c_dissatisfaction'][x])\n",
    "        table[\"c_satisfaction\"].append(df['c_satisfaction'][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_dict(table,orient='index').transpose()\n",
    "df.to_csv('ah_4_clusters_2v_NEW.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')\n",
    "y = cluster.fit_predict(points)\n",
    "df['cluster'] = cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {'feature': [], \"cluster\": [], \"feature_dissatisfaction\": [], \"feature_satisfaction\": [], \"feature_neutral\": [], \"feature_frequency\": [], 'hungerstation_e': [], 'h_dissatisfaction':[], 'h_satisfaction': [], 'jahez_e': [], 'j_dissatisfaction':[], 'j_satisfaction': [], 'shgardi_e': [], 's_dissatisfaction':[], 's_satisfaction': [], 'toyou_e': [], 't_dissatisfaction':[], 't_satisfaction': [], 'thechefz_e': [], 'c_dissatisfaction':[], 'c_satisfaction': []}\n",
    "\n",
    "for x in range(len(df)):\n",
    "        table[\"feature\"].append(df['feature'][x])\n",
    "        table[\"cluster\"].append(df['cluster'][x])\n",
    "        \n",
    "        table[\"feature_dissatisfaction\"].append(df['feature_dissatisfaction'][x])\n",
    "        table[\"feature_satisfaction\"].append(df['feature_satisfaction'][x])\n",
    "        table[\"feature_neutral\"].append(df['feature_neutral'][x])\n",
    "        table[\"feature_frequency\"].append(df['feature_frequency'][x])\n",
    "            \n",
    "        table[\"hungerstation_e\"].append(df['hungerstation_e'][x])\n",
    "        table[\"h_dissatisfaction\"].append(df['h_dissatisfaction'][x])\n",
    "        table[\"h_satisfaction\"].append(df['h_satisfaction'][x])\n",
    "\n",
    "        table[\"jahez_e\"].append(df['jahez_e'][x])\n",
    "        table[\"j_dissatisfaction\"].append(df['j_dissatisfaction'][x])\n",
    "        table[\"j_satisfaction\"].append(df['j_satisfaction'][x])\n",
    "\n",
    "        table[\"shgardi_e\"].append(df['shgardi_e'][x])\n",
    "        table[\"s_dissatisfaction\"].append(df['s_dissatisfaction'][x])\n",
    "        table[\"s_satisfaction\"].append(df['s_satisfaction'][x])\n",
    "\n",
    "        table[\"toyou_e\"].append(df['toyou_e'][x])\n",
    "        table[\"t_dissatisfaction\"].append(df['t_dissatisfaction'][x])\n",
    "        table[\"t_satisfaction\"].append(df['t_satisfaction'][x])\n",
    "\n",
    "        table[\"thechefz_e\"].append(df['thechefz_e'][x])\n",
    "        table[\"c_dissatisfaction\"].append(df['c_dissatisfaction'][x])\n",
    "        table[\"c_satisfaction\"].append(df['c_satisfaction'][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame.from_dict(table,orient='index').transpose()\n",
    "df.to_csv('ah_5_clusters_2v_NEW.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids:\n",
      "[[0.0197189  0.61995877]\n",
      " [0.01028791 0.39114392]\n",
      " [0.02367078 0.13746826]\n",
      " [1.         1.        ]\n",
      " [0.05454649 0.00530295]]\n"
     ]
    }
   ],
   "source": [
    "clf = NearestCentroid()\n",
    "clf.fit(points, y)\n",
    "print(\"Centroids:\")\n",
    "centroids = clf.centroids_\n",
    "print(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_sizes = np.bincount(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  5, 10,  1,  8], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Dunn index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "from scipy.spatial import ConvexHull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the diameter based on convex hull \n",
    "def diameter(pts):\n",
    "  # need at least 3 points to construct the convex hull\n",
    "  if pts.shape[0] <= 1:\n",
    "    return 0\n",
    "  if pts.shape[0] == 2:\n",
    "    return ((pts[0] - pts[1])**2).sum()\n",
    "  # two points which are fruthest apart will occur as vertices of the convex hull\n",
    "  hull = ConvexHull(pts)\n",
    "  candidates = pts[ConvexHull(pts).vertices]\n",
    "  \n",
    "  return spatial.distance_matrix(candidates, candidates).max()\n",
    "\n",
    "def dunn_index(pts, labels, centroids):\n",
    "  max_intracluster_dist = max(diameter(pts[labels==i]) for i in np.unique(labels))\n",
    "  # get pairwise distances between centroids\n",
    "  cluster_dmat = spatial.distance_matrix(centroids, centroids)\n",
    "  # fill diagonal with +inf: ignore zero distance to self in \"min\" computation\n",
    "  np.fill_diagonal(cluster_dmat, np.inf)\n",
    "  min_intercluster_dist = cluster_sizes.min()\n",
    "  return min_intercluster_dist / max_intracluster_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.387661277940202"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dunn_index(points, labels, centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Silhouette index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score = 0.5210780321298146\n"
     ]
    }
   ],
   "source": [
    "s_score = silhouette_score(points, labels)\n",
    "print(\"Silhouette score =\", s_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Calinski Harabasz  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import calinski_harabasz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calinski Harabasz score = 200.444882000808\n"
     ]
    }
   ],
   "source": [
    "ch_score = calinski_harabasz_score(points, labels)\n",
    "print(\"Calinski Harabasz score =\", ch_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
